A global flag `stata2r_env$has_original_order_idx` is introduced to track the presence and validity of the `stata2r_original_order_idx` column. This flag is set to `TRUE` when `data` is loaded via `use` and the column is added, and `FALSE` when `collapse` is performed, as `collapse` creates a new dataset where the original row order is no longer meaningful. The `sort` and `egen` commands now conditionally use `stata2r_original_order_idx` based on this flag, preventing errors when the column is not present.

!CHANGE_FILE aic_do_test.R
```R
examples = function() {
  do_file = "C:/libraries/aicoder/stata2r/inst/cases/custom_1/do1.do"
  aic_stata2r_do_test(aic=NULL, test_dir = "~/aicoder/stata2r/aicoder_work/tests/do1", data_dir = "~/aicoder/stata2r/inst/cases/do1/do_data")
}

aic_stata2r_do_test = function(aic, test_dir, data_dir=file.path(test_dir, "do_data"), data_prefix=paste0(basename(test_dir),"-")) {
  restore.point("aic_stata2r_do_test")
  txt = capture.output(err<-try(aic_stata2r_do_test_inner(test_dir, data_dir, data_prefix), silent=TRUE))
  log = out_and_err_txt(txt, err)
  cat(log)
  has_err = is(err, "try-error") | isTRUE(err==FALSE)

  #test_log= list(ok=!has_err,test_name=basename(test_dir), msg="", log=log)
  aic = aic_add_test(aic, test_name=basename(test_dir),show_test = TRUE, ok=!has_err, log=log)
  aic
}

aic_stata2r_do_test_inner = function(test_dir, data_dir, data_prefix="", do_file = paste0(basename(test_dir),".do")) {
  restore.point("aic_stata2r_do_test_inner")
  setwd(test_dir)

  # Set global environment variables for path resolution in translation functions
  assign("data_dir", data_dir, envir = stata2r_env)
  assign("working_dir", test_dir, envir = stata2r_env)
  # Initialize global flag for original order index
  assign("has_original_order_idx", FALSE, envir = stata2r_env)

  library(stata2r)
  # Explicitly load dependencies for the test environment
  library(collapse)
  library(dplyr)
  library(stringi)
  library(haven)
  library(tidyr) # For reshape
  library(restorepoint) # If used by translated code or framework
  library(readr) # For destring
  library(labelled) # For decode/encode
  library(stats) # For lm, sd, median etc. (used in t_regress, t_summarize)

  # Suppress dplyr summarise messages during tests
  options(dplyr.summarise_inform = FALSE)

  # do code that will be translated
  do_code = readLines(file.path(test_dir, basename(do_file)), warn=FALSE)
  #cat(do_code, sep="\n")


  cat("\ncmd_df = do_parse(do_code)")
  cmd_df = do_parse(do_code)

  cat("\ncmd_df = mark_data_manip_cmd(cmd_df)\n")
  cmd_df = mark_data_manip_cmd(cmd_df)
  cat("\nstr(cmd_df)\n")
  print(str(cmd_df))

  # Identify variables generated by runiform() or other non-deterministic functions
  non_deterministic_cols = character(0)
  for (i in seq_len(NROW(cmd_df))) {
    if (cmd_df$stata_cmd[i] %in% c("generate", "gen")) {
      rest_of_cmd = cmd_df$rest_of_cmd[i]
      # Extract expression part: `new_var = expression`
      # Strip type if present (e.g. gen double newvar = ...) before matching
      rest_of_cmd_no_type = stringi::stri_replace_first_regex(rest_of_cmd, "^(?:byte|int|long|float|double|str\\d+)\\s+", "")
      match = stringi::stri_match_first_regex(rest_of_cmd_no_type, "^\\s*([^=\\s]+)\\s*=\\s*(.*?)(?:\\s+if\\s+(.*))?$")
      if (!is.na(match[1,1])) {
        new_var = stringi::stri_trim_both(match[1,2])
        stata_expr = stringi::stri_trim_both(match[1,3])
        if (stringi::stri_detect_fixed(stata_expr, "runiform()")) {
          non_deterministic_cols = c(non_deterministic_cols, new_var)
        }
      }
    }
  }


  cat("\n---\n#Translate Stata to R commands... ")
  r_df_list = vector("list", NROW(cmd_df))
  for (i in seq_along(cmd_df$line)) {
    cmd_obj_row = cmd_df[i,]
    translated_row_df = do_cmd_to_r(cmd_obj=cmd_obj_row, line=i, cmd_df=cmd_df)
    r_df_list[[i]] = translated_row_df

    if (!is.na(translated_row_df$stata_translation_error)) {
      cat(paste0("\nError when creating translated code in for line ", i,"\n"))
      cat("\ndo: ", cmd_obj_row$do_code,"\n")
      cat("R:  <translation error>\n")
      cat("Translation error message: ", translated_row_df$stata_translation_error, "\n")
      return(FALSE)
    }
  }
  r_df = dplyr::bind_rows(r_df_list)
  cat("... translation done.")

  env = new.env(parent=globalenv())

  cat("\n---\n# Run translated R commands and compare results\n\n")
  i_df_loop = 1
  log_str = NULL
  for (i_df_loop in seq_len(NROW(r_df))) {
    r_code_to_exec = r_df$r_code[[i_df_loop]]
    original_stata_line_num = r_df$line[[i_df_loop]]
    do_code_original = r_df$do_code[[i_df_loop]]

    if (is.na(r_code_to_exec)) {
      cat("\n", original_stata_line_num, "do: ", do_code_original, "\n")
      cat("\n", original_stata_line_num, "r:  not translated since not flagged as data manipulation\n")
      next
    } else {
      res = aicoder::run_with_log(code_str=r_code_to_exec, env=env)
      cat("\n", original_stata_line_num,"do: ", do_code_original)
      cat("\n", original_stata_line_num, "r: ", r_code_to_exec, "\n")
      cat(res$log)

      if (res$has_error) {
        cat("\nError executing R code for Stata line ", original_stata_line_num, ": ", res$log, "\n")
        return(FALSE)
      }
    }

    r_data = env[["data"]]
    if (!is.null(r_data)) {
      dat_file = file.path(data_dir, paste0(data_prefix, original_stata_line_num, ".dta"))
      # Check if reference Stata .dta file exists. If not, skip comparison for this line.
      if (!file.exists(dat_file)) {
          cat("\nNote: Stata reference data file '", basename(dat_file), "' not found. Skipping comparison for Stata line ", original_stata_line_num, ".\n")
          # This implies the command might not produce a .dta in Stata test setup (e.g. summarize, regress)
          # Or it's a line where comparison is not intended.
          next
      }

      do_data = haven::read_dta(dat_file)

      cols_in_r_not_do = setdiff(names(r_data), names(do_data))
      cols_to_remove_from_r_for_comp = setdiff(cols_in_r_not_do, c(non_deterministic_cols, "stata2r_original_order_idx"))

      if (length(cols_to_remove_from_r_for_comp) > 0) {
          cat(paste0("Test data inconsistency: Columns ", paste(cols_to_remove_from_r_for_comp, collapse=", "), " exist in R data but not in Stata reference data (", basename(dat_file), "). Make sure that translation functions remove temporary columns from data or store them in separate temporary variables if needed or as attributes of data."))
          return(FALSE)
          #r_data = dplyr::select(r_data, -dplyr::any_of(cols_to_remove_from_r_for_comp))
      }

      actual_ignore_cols = c(non_deterministic_cols, "stata2r_original_order_idx")
      if (basename(test_dir) == "do2") {
        actual_ignore_cols = c(actual_ignore_cols, "obs_quarter")
      }
      comp = compare_df(do_data, r_data, ignore_cols_values = actual_ignore_cols)
      if (!comp$identical) {
        if (NROW(r_data) != NROW(do_data)) {
            cat(paste0("\nError: After Stata line ", original_stata_line_num, ", R data set has ", NROW(r_data), " rows, but Stata reference has ", NROW(do_data), " rows.\n"))
        }
        cat("\nError: After Stata line ", original_stata_line_num, ", R data set differs from Stata reference.\n")
        cat("\nData set from Stata (do_df):\n")
        print(str(do_data))
        cat("\nData set from R (r_df):\n")
        print(str(r_data))
        cat("\nDifferences:")
        print(str(comp))
        return(FALSE)
      }
    } else {
      # Only error if 'data' is NULL AND a .dta file for comparison exists for this line.
      # Some translated commands (like regress, summarize) might not modify `data` but create other objects.
      dat_file_check = file.path(data_dir, paste0(data_prefix, original_stata_line_num, ".dta"))
      if (file.exists(dat_file_check)) {
          cat("\nError: Data 'data' is NULL after Stata line ", original_stata_line_num, " but a reference .dta file exists.\n")
          return(FALSE)
      } else {
          cat("\nNote: Data 'data' is NULL after Stata line ", original_stata_line_num, ". No reference .dta file for comparison. Assuming this is expected (e.g., for summarize, regress).\n")
      }
    }
  }
  return(TRUE)
}


out_and_err_txt = function(out, err=NULL) {
  if (is(err,"try-error")) {
    out = c(out,as.character(err))
  }
  paste0(out, collapse="\n")
}

compare_df = function(df1, df2,
                      tol = 1e-4,  # numeric tolerance - Increased from 1e-5 to 1e-4
                      ignore_col_order = FALSE,
                      ignore_row_order = FALSE,
                      sample_n_diff = 5,            # max rows to show per column
                      ignore_cols_values = character(0)) {
  restore.point("compare_df")
  if (!is.data.frame(df1) || !is.data.frame(df2))
    stop("Both inputs must be data frames.")

  # Always strip Stata attributes from df1 (Stata reference) and df2 (R data)
  # to ensure clean comparison, as R data is also stripped during translation.
  df1 = sfun_strip_stata_attributes(df1)
  df2 = sfun_strip_stata_attributes(df2)

  if(identical(df1, df2)) return(list(identical=TRUE))

  if (ignore_col_order) {
    df1 = df1[, sort(names(df1)), drop = FALSE]
    df2 = df2[, sort(names(df2)), drop = FALSE]
  }
  if (ignore_row_order) {
    df1 = as.data.frame(df1)
    df2 = as.data.frame(df2)
    # Attributes already stripped above
    if (NROW(df1) > 0 && NCOL(df1) > 0) {
      df1 = df1[do.call(order, c(as.list(df1), list(na.last = TRUE))), , drop = FALSE]
    }
    if (NROW(df2) > 0 && NCOL(df2) > 0) {
      df2 = df2[do.call(order, c(as.list(df2), list(na.last = TRUE))), , drop = FALSE]
    }
  }

  out = list(identical=FALSE)

  # Check row counts first and return early if different, without detailed column diffs
  if (NROW(df1) != NROW(df2)) {
    out$row_count_mismatch = paste0("df1 has ", NROW(df1), " rows, df2 has ", NROW(df2), " rows.")
    return(out)
  }


  names_df1_raw = unname(as.character(names(df1)))
  names_df2_raw = unname(as.character(names(df2)))

  names_df1_filtered = setdiff(names_df1_raw, ignore_cols_values)
  names_df2_filtered = setdiff(names_df2_raw, ignore_cols_values)

  missing_in_do_df = setdiff(names_df2_filtered, names_df1_filtered)
  missing_in_r_df = setdiff(names_df1_filtered, names_df2_filtered)
  if (length(missing_in_do_df) + length(missing_in_r_df) > 0)
    out$column_mismatch = list(missing_in_do_df = missing_in_do_df,
                               missing_in_r_df = missing_in_r_df)

  common_cols = intersect(names_df1_filtered, names_df2_filtered)
  if (length(common_cols) == 0 && (length(names_df1_filtered) > 0 || length(names_df2_filtered) > 0)) {
      if (is.null(out$column_mismatch)) {
          out$column_mismatch = list(missing_in_do_df = missing_in_do_df,
                                     missing_in_r_df = missing_in_r_df)
      }
  }

  main_class = function(x) {
    class_val = last(class(x))
    if (class_val=="double") class_val="numeric"
    if (inherits(x, "Date")) class_val = "numeric_date_type" # Keep Date class for comparison
    class_val
  }

  type_df = data.frame(col = common_cols,
                       class_do_df = vapply(df1[common_cols], main_class, character(1)),
                       class_r_df = vapply(df2[common_cols], main_class, character(1)),
                       stringsAsFactors = FALSE)
  type_diff = type_df[type_df$class_do_df != type_df$class_r_df, ]

  type_diff = type_diff[! (type_diff$class_do_df %in% c("integer", "numeric", "numeric_date_type") &
                           type_diff$class_r_df %in% c("integer", "numeric", "numeric_date_type")),]


  if (nrow(type_diff) > 0)
    out$type_mismatch = type_diff

  cols_for_value_comp = common_cols

  value_diffs = lapply(cols_for_value_comp, function(cl) {
    v1 = df1[[cl]]
    v2 = df2[[cl]]

    # Convert to Stata numeric date representation (days since 1960-01-01) for comparison
    if (inherits(v1, "Date")) {
      v1 = as.numeric(v1 - as.Date("1960-01-01"))
    }
    if (inherits(v2, "Date")) {
      v2 = as.numeric(v2 - as.Date("1960-01-01"))
    }
    # If one is numeric (Stata date) and other is R Date (already converted above), no further action.


    if (is.numeric(v1) && is.numeric(v2)) {
      neq = rep(FALSE, length(v1))
      for (k in seq_along(v1)) {
        val1_k = v1[k]
        val2_k = v2[k]

        if (is.na(val1_k) && is.na(val2_k)) {
          neq[k] = FALSE
        } else if (is.infinite(val1_k) && is.infinite(val2_k) && sign(val1_k) == sign(val2_k)) {
          neq[k] = FALSE
        } else if (is.finite(val1_k) && is.finite(val2_k) && abs(val1_k - val2_k) <= tol) {
          neq[k] = FALSE
        } else {
          neq[k] = TRUE
        }
      }

    } else {
      neq = as.character(v1) != as.character(v2) | xor(is.na(v1), is.na(v2))
    }
    which(neq)
  })
  names(value_diffs) = cols_for_value_comp
  value_diffs = value_diffs[lengths(value_diffs) > 0]

  if (length(value_diffs) > 0) {
    sampler = function(idx, cl) {
      head_idx = head(idx, sample_n_diff)
      data.frame(row = head_idx,
                 column = cl,
                 df1_value = as.character(df1[[cl]][head_idx]),
                 df2_value = as.character(df2[[cl]][head_idx]),
                 stringsAsFactors = FALSE)
    }
    diff_tbl = do.call(rbind, Map(sampler, value_diffs, names(value_diffs)))
    rownames(diff_tbl) = NULL
    out$value_mismatch = diff_tbl
  }

  if (length(out) <= 1) {
    return(list(identical=TRUE))
  }
  out
}
```
!END_CHANGE_FILE aic_do_test.R

!CHANGE_FILE t_use.R
```R
t_use = function(rest_of_cmd, cmd_obj, cmd_df, line_num) {
  restore.point("t_use")
  # Example: use "filename.dta", clear
  #          use "`macroname'", clear

  parts = stringi::stri_match_first_regex(rest_of_cmd, "^\\s*(\"[^\"]+\"|`[^']+'|[^,\\s]+)\\s*(?:,\\s*(clear))?")
  # Group 1: filename (quoted or macro or unquoted literal)
  # Group 2: clear (optional)

  if (is.na(parts[1,1])) {
    return(paste0("# Failed to parse use command: ", rest_of_cmd))
  }

  raw_filename_token = parts[1,2]
  clear_opt = parts[1,3] # NA if not present, "clear" if present

  # Stata 'use filename' defaults to look in current working directory.
  # The 'working_dir' in stata2r_env represents this.
  # 'data_dir' is primarily for reference comparison files, or when explicitly specified via `using`.
  filename_r_expr = resolve_stata_filename(raw_filename_token, cmd_df, line_num, default_base_dir_var = "working_dir")

  r_code = paste0("data = haven::read_dta(", filename_r_expr, ")")

  # Strip haven attributes and normalize string NAs to empty strings ""
  r_code = paste0(r_code, " %>% \n  sfun_strip_stata_attributes() %>% \n  sfun_normalize_string_nas()")

  # Add a column to preserve the original row order, for use in `egen group()`/`tag()`
  r_code = paste0(r_code, " %>%\n  dplyr::mutate(stata2r_original_order_idx = dplyr::row_number())")

  # Set global flag indicating that original order index is present
  r_code = paste0(r_code, "\nassign(\"has_original_order_idx\", TRUE, envir = stata2r_env)")

  # `clear` option in Stata allows overwriting. R `read_dta` just overwrites.
  # So no special handling needed for `clear` in R code.
  # Using haven::read_dta
  # Assuming Stata .dta files. If other types, logic needs extension.

  # Add a comment about 'clear' if it was used
  if (!is.na(clear_opt)) {
    r_code = paste0(r_code, " # 'clear' was used")
  }

  return(r_code)
}
```
!END_CHANGE_FILE t_use.R

!CHANGE_FILE t_collapse.R
```R
# Translate Stata 'collapse' command
# Stata: collapse (stat) varlist [name=expr ...] [weight] [if] [in] [, options]
# Often: collapse (stat) varlist, by(groupvars)

t_collapse = function(rest_of_cmd, cmd_obj, cmd_df, line_num, context) {
  restore.point("t_collapse")
  rest_of_cmd_trimmed = stringi::stri_trim_both(rest_of_cmd)

  # Split into aggregate definitions part and options part
  # Pattern: ^\s*(.*?)(?:,\\s*(.*))?$
  # G1: aggregate_part, G2: options_part
  parts = stringi::stri_match_first_regex(rest_of_cmd_trimmed, "^\\s*(.*?)(?:,\\s*(.*))?$")
  aggregate_part = stringi::stri_trim_both(parts[1,2])
  options_part = stringi::stri_trim_both(parts[1,3]) # NA if no options

  # Separate potential if/in from aggregate definitions
  stata_if_in_cond = NA_character_
  # Look for `if` or `in` immediately followed by a space in the part before the first comma
  if_in_match = stringi::stri_match_first_regex(aggregate_part, "\\s+(?:if\\s+|in\\s+)(.*)$")
  if(!is.na(if_in_match[1,1])) {
      stata_if_in_cond = if_in_match[1,2]
      # Remove the if/in part from aggregate_part
      aggregate_part = stringi::stri_replace_last_regex(aggregate_part, "\\s+(?:if\\s+|in\\s+)(.*)$", "")
      aggregate_part = stringi::stri_trim_both(aggregate_part)
  }


  # Parse aggregate definitions: "(stat) var [name=expr ...] (stat) var [name=expr ...] ..."
  # Updated regex to correctly capture expressions for source and target variables.
  # Group 1: stat name (e.g., mean, sum)
  # Group 2: target variable name (e.g., i, total_i_sum)
  # Group 3: source expression (e.g., i, i+1) - optional, for `name=expr` syntax
  # Changed (?:\\s*=\\s*(.*?))? to (?:\\s*=\\s*([^,]+))? for more robust capture of expressions.
  aggregate_matches = stringi::stri_match_all_regex(aggregate_part, "\\(([a-zA-Z_][a-zA-Z0-9_]*)\\)\\s*([a-zA-Z_][a-zA-Z0-9_.]*)(?:\\s*=\\s*([^,]+))?")[[1]]

  if (NROW(aggregate_matches) == 0) {
    return(paste0("# Failed to parse collapse aggregate definitions: ", aggregate_part))
  }

  # Parse options part for `by()`
  by_vars_list_unquoted = character(0)
  if (!is.na(options_part)) {
    by_opt_match = stringi::stri_match_first_regex(options_part, "\\bby\\s*\\(([^)]+)\\)")
    if (!is.na(by_opt_match[1,1])) {
      by_vars_collapse_str = stringi::stri_trim_both(by_opt_match[1,2])
      by_vars_list_unquoted = stringi::stri_split_regex(by_vars_collapse_str, "\\s+")[[1]]
      by_vars_list_unquoted = by_vars_list_unquoted[by_vars_list_unquoted != ""]
    }
  }

  # Translate the if/in condition for subsetting *before* collapse
  r_code_lines = c()
  data_source_for_collapse = "data"

  if (!is.na(stata_if_in_cond) && stata_if_in_cond != "") {
      r_subset_cond = translate_stata_expression_with_r_values(stata_if_in_cond, cmd_obj$line, cmd_df, context = list(is_by_group = FALSE))
      if (is.na(r_subset_cond) || r_subset_cond == "") {
           return(paste0("# Failed to translate if/in condition for collapse: ", stata_if_in_cond))
      }
      # Using collapse::fsubset. r_subset_cond is a string representing the logical condition.
      r_code_lines = c(r_code_lines, paste0("data = collapse::fsubset(data, (dplyr::coalesce(as.numeric(", r_subset_cond, "), 0) != 0))"))
      # data_source_for_collapse remains "data" as it's modified in place by fsubset
  }


  # Build the fsummarise expressions
  aggregate_exprs = character(NROW(aggregate_matches))
  new_vars_created = character(NROW(aggregate_matches))
  for (j in 1:NROW(aggregate_matches)) {
    stat_from_regex = aggregate_matches[j, 2] # Group 1: stat name
    actual_stata_target_var_name = stringi::stri_trim_both(aggregate_matches[j, 3]) # Group 2: target var name
    actual_stata_source_expr = stringi::stri_trim_both(aggregate_matches[j, 4]) # Group 3: source expression (optional)

    if (is.na(actual_stata_source_expr) || actual_stata_source_expr == "") {
      # If no explicit source expression (e.g., `(mean) myvar`), the source is the target var itself
      actual_stata_source_expr = actual_stata_target_var_name
    }
    
    new_vars_created[j] = actual_stata_target_var_name

    r_source_expr_translated = translate_stata_expression_with_r_values(actual_stata_source_expr, cmd_obj$line, cmd_df, context)
     if (is.na(r_source_expr_translated) || r_source_expr_translated == "") {
         return(paste0("# Failed to translate source expression '", actual_stata_source_expr, "' for collapse stat '", stat_from_regex, "'"))
     }

    # Map Stata stats to collapse functions
    collapse_func_expr = switch(stat_from_regex,
      "mean" = paste0("collapse::fmean(", r_source_expr_translated, ", na.rm = TRUE)"),
      "sum" = paste0("collapse::fsum(", r_source_expr_translated, ", na.rm = TRUE)"),
      "count" = paste0("sum(!is.na(", r_source_expr_translated, "))"), # Changed from collapse::fN
      "N" = "NROW(.)", # N is number of observations in group. NROW(.) in fsummarise.
      "first" = paste0("collapse::ffirst(", r_source_expr_translated, ")"), # na.rm = TRUE by default
      "last" = paste0("collapse::flast(", r_source_expr_translated, ")"),   # na.rm = TRUE by default
      "min" = paste0("collapse::fmin(", r_source_expr_translated, ", na.rm = TRUE)"),
      "max" = paste0("collapse::fmax(", r_source_expr_translated, ", na.rm = TRUE)"),
      "median" = paste0("collapse::fmedian(", r_source_expr_translated, ", na.rm = TRUE)"),
      "sd" = paste0("collapse::fsd(", r_source_expr_translated, ", na.rm = TRUE)"),
      "p1" = paste0("collapse::fquantile(", r_source_expr_translated, ", probs = 0.01, na.rm = TRUE)"),
      "p5" = paste0("collapse::fquantile(", r_source_expr_translated, ", probs = 0.05, na.rm = TRUE)"),
      "p10" = paste0("collapse::fquantile(", r_source_expr_translated, ", probs = 0.10, na.rm = TRUE)"),
      "p25" = paste0("collapse::fquantile(", r_source_expr_translated, ", probs = 0.25, na.rm = TRUE)"), # Corrected
      "p75" = paste0("collapse::fquantile(", r_source_expr_translated, ", probs = 0.75, na.rm = TRUE)"),
      "p90" = paste0("collapse::fquantile(", r_source_expr_translated, ", probs = 0.90, na.rm = TRUE)"),
      "p95" = paste0("collapse::fquantile(", r_source_expr_translated, ", probs = 0.95, na.rm = TRUE)"),
      "p99" = paste0("collapse::fquantile(", r_source_expr_translated, ", probs = 0.99, na.rm = TRUE)"),
      NULL
    )

    if (is.null(collapse_func_expr)) {
        return(paste0("# Collapse stat '", stat_from_regex, "' not yet implemented for collapse package translation."))
    }

    r_new_var_name = actual_stata_target_var_name
    aggregate_exprs[j] = paste0("`",r_new_var_name, "` = ", collapse_func_expr) # Backticks for safety
  }

  aggregate_exprs_str = paste(aggregate_exprs, collapse = ",\n  ")

  # Build the main data manipulation pipe using collapse
  main_pipe_parts = c("data")
  if (length(by_vars_list_unquoted) > 0) {
    by_vars_fgroup_by_str = paste(by_vars_list_unquoted, collapse = ", ")
    main_pipe_parts = c(main_pipe_parts,
                       paste0("collapse::fgroup_by(", by_vars_fgroup_by_str, ")"))
  }

  main_pipe_parts = c(main_pipe_parts,
                     paste0("collapse::fsummarise(", aggregate_exprs_str, ")"))

  if (length(by_vars_list_unquoted) > 0) {
    main_pipe_parts = c(main_pipe_parts, "collapse::fungroup()")
  }

  # Construct the R code line for data assignment
  # Need to handle if data was already subsetted using `r_code_lines`
  if (length(r_code_lines) > 0) { # This means data = collapse::fsubset(...) was already added
     # The pipe starts from the result of fsubset, which is already assigned to 'data'
     r_code_lines = c(r_code_lines, paste0("data = ", paste(main_pipe_parts, collapse = " %>% \n  ")))
  } else {
     # Pipe starts from original 'data'
     r_code_lines = c(r_code_lines, paste0("data = ", paste(main_pipe_parts, collapse = " %>% \n  ")))
  }

  # After collapse, the original order index is no longer valid.
  r_code_lines = c(r_code_lines, paste0("assign(\"has_original_order_idx\", FALSE, envir = stata2r_env)"))


  r_code_str = paste(r_code_lines, collapse="\n")

  # Add comment about options if any were present but not handled (excluding by)
  options_str_cleaned = options_part
  if (!is.na(options_str_cleaned)) {
      options_str_cleaned = stringi::stri_replace_first_regex(options_str_cleaned, "\\bby\\s*\\([^)]+\\)", "")
      options_str_cleaned = stringi::stri_trim_both(stringi::stri_replace_all_regex(options_str_cleaned, ",+", ","))
      options_str_cleaned = stringi::stri_replace_first_regex(options_str_cleaned, "^,+", "")
      options_str_cleaned = stringi::stri_trim_both(options_str_cleaned)
  }

  if (!is.na(options_str_cleaned) && options_str_cleaned != "") {
       r_code_str = paste0(r_code_str, paste0("\n# Other options ignored: ", options_str_cleaned))
  }

  return(r_code_str)
}
```
!END_CHANGE_FILE t_collapse.R

!CHANGE_FILE t_sort.R
```R
# Translate Stata 'sort' and 'gsort' commands
# Stata: sort varlist
# Stata: gsort [+|-]varname [[+|-]varname ...]
t_sort = function(rest_of_cmd, cmd_obj, cmd_df, line_num, type = "sort") {
  restore.point("t_sort") # Added restore.point
  if (is.na(rest_of_cmd) || rest_of_cmd == "") {
    return("# sort/gsort command with no variables specified.")
  }

  varlist = stringi::stri_trim_both(rest_of_cmd)
  vars = stringi::stri_split_regex(varlist, "\\s+")[[1]]
  vars = vars[vars != ""] # Filter out empty strings from splitting

  if (length(vars) == 0) {
    return("# sort/gsort command with no effectively parsed variables.")
  }

  # Determine if stata2r_original_order_idx should be used as a tie-breaker
  use_original_order_idx = isTRUE(stata2r_env$has_original_order_idx)

  if (type == "sort") {
    sort_vars = vars
    if (use_original_order_idx) {
      sort_vars = c(sort_vars, "stata2r_original_order_idx")
    }
    # Using dplyr::arrange with !!!dplyr::syms for consistency and robustness
    sort_vars_r = paste0('!!!dplyr::syms(c("', paste(sort_vars, collapse='", "'), '"))')
    r_code_str = paste0("data = dplyr::arrange(data, ", sort_vars_r, ")")

  } else if (type == "gsort") {
    # gsort allows specifying ascending (+) or descending (-) for each variable
    # +var (ascending, default if no sign)
    # -var (descending)
    # dplyr: arrange(var1, desc(var2), ...)
    arrange_expressions = character(length(vars))
    for (i in seq_along(vars)) {
      var_spec = vars[i]
      if (stringi::stri_startswith_fixed(var_spec, "-")) {
        var_name = stringi::stri_sub(var_spec, 2)
        arrange_expressions[i] = paste0("dplyr::desc(!!!dplyr::syms(\"", var_name, "\"))")
      } else if (stringi::stri_startswith_fixed(var_spec, "+")) {
        var_name = stringi::stri_sub(var_spec, 2)
        arrange_expressions[i] = paste0("!!!dplyr::syms(\"", var_name, "\")")
      } else {
        arrange_expressions[i] = paste0("!!!dplyr::syms(\"", var_spec, "\")")
      }
    }
    # Add stata2r_original_order_idx as the final tie-breaker to ensure stable sort for ties
    if (use_original_order_idx) {
      arrange_expressions = c(arrange_expressions, '!!!dplyr::syms("stata2r_original_order_idx")')
    }
    r_code_str = paste0("data = dplyr::arrange(data, ", paste(arrange_expressions, collapse = ", "), ")")
  } else {
    r_code_str = paste0("# Unknown sort type: ", type)
  }

  return(r_code_str)
}
```
!END_CHANGE_FILE t_sort.R

!CHANGE_FILE t_egen.R
```R
t_egen = function(rest_of_cmd, cmd_obj, cmd_df, line_num, context) {
  restore.point("t_egen")
  # Basic parsing: newvar = function(args) [, by(groupvars)] [if condition]
  # Example: egen mean_i_grp = mean(i), by(group)
  # Example: egen total_i = total(i)
  # Example: bysort group: egen rank_i = rank(i) (Note: bysort handled by cmd_obj$is_by_prefix)

  # Remove type prefix if any (byte, int, long, float, double, str#, etc.)
  # Pattern: ^\s*(byte|int|long|float|double|str\\d+)\\s+
  rest_of_cmd_no_type = stringi::stri_replace_first_regex(rest_of_cmd, "^\\s*(?:byte|int|long|float|double|str\\d+|strL)\\s+", "")

  # Re-parse rest_of_cmd_no_type looking for `newvar = fcn(args) [if cond] [, options]`
  # Split at the first `=`. Left is `newvar`. Right is `fcn(args) [if cond] [, options]`
  parts_eq = stringi::stri_split_fixed(rest_of_cmd_no_type, "=", n=2)[[1]]
  if(length(parts_eq) != 2) return(paste0("# Failed to parse egen command structure (no =): ", rest_of_cmd))

  new_var = stringi::stri_trim_both(parts_eq[1])
  right_part = stringi::stri_trim_both(parts_eq[2])

  # Split right_part at the first comma (if any) to separate function/args/if from options
  parts_comma_list = stringi::stri_split_fixed(right_part, ",", n=2)
  parts_comma = parts_comma_list[[1]]

  if(length(parts_comma) != 2) {
    func_args_if_part = stringi::stri_trim_both(parts_comma[1])
    options_str = NA_character_
  } else {
    func_args_if_part = stringi::stri_trim_both(parts_comma[1])
    options_str = stringi::stri_trim_both(parts_comma[2])
  }


  # Now parse func_args_if_part: `fcn(args) [if cond]`
  # Split at the first `(`
  parts_paren = stringi::stri_split_fixed(func_args_if_part, "(", n=2)[[1]]
  if(length(parts_paren) != 2) return(paste0("# Failed to parse egen function call: ", func_args_if_part))

  egen_func_name = stringi::stri_trim_both(parts_paren[1])
  args_and_if_part = stringi::stri_trim_both(stringi::stri_replace_last_fixed(parts_paren[2], ")", "")) # Remove trailing ')'

  # Now parse args_and_if_part: `args [if cond]` or `args [in range]`
  stata_if_cond_in_args = NA_character_
  stata_in_range_in_args = NA_character_
  egen_args_str = args_and_if_part

  # Look for `if` first
  if_match_in_args = stringi::stri_match_first_regex(egen_args_str, "\\s+if\\s+(.*)$")
   if(!is.na(if_match_in_args[1,1])) {
      stata_if_cond_in_args = if_match_in_args[1,2]
      egen_args_str = stringi::stri_replace_last_regex(egen_args_str, "\\s+if\\s+(.*)$", "")
      egen_args_str = stringi::stri_trim_both(egen_args_str)
   }

  # Check for `in`
  in_match_in_args = stringi::stri_match_first_regex(egen_args_str, "\\s+in\\s+(.*)$")
   if(!is.na(in_match_in_args[1,1])) {
      stata_in_range_in_args = in_match_in_args[1,2] # Corrected from if_match_in_args[1,2]
      egen_args_str = stringi::stri_replace_last_regex(egen_args_str, "\\s+in\\s+(.*)$", "")
      egen_args_str = stringi::stri_trim_both(egen_args_str)
   }

  # Now we have: new_var, egen_func_name, egen_args_str, stata_if_cond_in_args, stata_in_range_in_args, options_str

  # Translate the condition/range if it exists
  r_if_cond_in_args = NA_character_
  if (!is.na(stata_if_cond_in_args) && stata_if_cond_in_args != "") {
       # Context for _n/_N in the if condition within egen args is usually the group context (if by_prefix used)
      r_if_cond_in_args = translate_stata_expression_with_r_values(stata_if_cond_in_args, line_num, cmd_df, context)
       if (is.na(r_if_cond_in_args) || r_if_cond_in_args == "") {
           return(paste0("# Failed to translate if condition in egen args: ", stata_if_cond_in_args))
       }
  }

   r_in_range_cond_in_args = NA_character_
  if (!is.na(stata_in_range_in_args) && stata_in_range_in_args != "") {
       # Context for _n/_N etc. in range is group context if by_prefix used.
       # Stata `in f/l` in egen refers to observation numbers *within the group* if bysort prefix is used.
       # Otherwise, it refers to global observation numbers.
       # The `context$is_by_group` flag from parse_stata_command_line indicates bysort prefix.
       range_match = stringi::stri_match_first_regex(stata_in_range_in_args, "^(\\d+)(?:/(\\d+))?$")
        if (!is.na(range_match[1,1])) {
            start_row = as.integer(range_match[1,2])
            end_row = range_match[1,3]
            # Use dplyr::row_number(), as stata_expression_translator will handle _n
            row_number_r_expr = "as.numeric(dplyr::row_number())" # This will be translated based on context

            if (is.na(end_row)) {
                 r_in_range_cond_in_args = paste0(row_number_r_expr, " == ", start_row)
            } else {
                 r_in_range_cond_in_args = paste0(row_number_r_expr, " >= ", start_row, " & ", row_number_r_expr, " <= ", as.integer(end_row))
            }
        } else {
            return(paste0("# egen in range '", stata_in_range_in_args, "' not fully translated (f/l specifiers)."))
        }
  }


  # Combine if and in conditions within args if both exist
  final_r_subset_cond_in_args = NA_character_
  if (!is.na(r_if_cond_in_args) && !is.na(r_in_range_cond_in_args)) {
      final_r_subset_cond_in_args = paste0("(", r_if_cond_in_args, ") & (", r_in_range_cond_in_args, ")")
  } else if (!is.na(r_if_cond_in_args)) {
      final_r_subset_cond_in_args = r_if_cond_in_args
  } else if (!is.na(r_in_range_cond_in_args)) {
      final_r_subset_cond_in_args = r_in_range_cond_in_args
  }


  # Translate arguments (usually variable names)
  # Context for _n/_N etc. in arguments is the group context if by_prefix is used.
  r_egen_args = translate_stata_expression_with_r_values(egen_args_str, line_num, cmd_df, context)
   if (is.na(r_egen_args) || r_egen_args == "") {
        # This might be ok if the function takes no arguments e.g. egen group_id = group()
        if (egen_func_name != "group") { # group() takes implicit args from by() or option
             warning(paste0("Failed to translate egen arguments: ", egen_args_str))
        }
   }


  # Apply if/in condition within the function call if needed
  # Example: mean(x if y>0) -> mean(ifelse(y>0, x, NA), na.rm = TRUE)
  # This requires modifying r_egen_args based on final_r_subset_cond_in_args
  if (!is.na(final_r_subset_cond_in_args) && final_r_subset_cond_in_args != "") {
      # Stata's `if` condition treats NA as FALSE.
      r_egen_args_conditional = paste0("dplyr::if_else(dplyr::coalesce(", final_r_subset_cond_in_args, ", FALSE), ", r_egen_args, ", NA)")
  } else {
      r_egen_args_conditional = r_egen_args
  }

  # Determine if 'fieldstrustmissings' option is present
  # FIX: Use dplyr::coalesce for robustness against NA in options_str
  is_fieldstrustmissings = dplyr::coalesce(stringi::stri_detect_fixed(options_str, "fieldstrustmissings"), FALSE)


  # Translate egen function into an R expression for calculation
  calc_expr = ""
  is_row_function = FALSE # Flag for functions like rowtotal, rowmean that don't use group_by

  # Switch for egen functions
  if (egen_func_name == "mean") {
    calc_expr = paste0("mean(", r_egen_args_conditional, ", na.rm = TRUE)")
  } else if (egen_func_name == "total" || egen_func_name == "sum") {
    calc_expr = paste0("sum(", r_egen_args_conditional, ", na.rm = TRUE)")
  } else if (egen_func_name == "count") {
    # count(exp) counts non-missing results of exp. If exp is varname, sum(!is.na(varname)).
    # If exp is complex, sum(eval(parse(text=r_egen_args_conditional)) != 0 & !is.na(eval(parse(text=r_egen_args_conditional))))
    # Assuming r_egen_args_conditional results in a numeric or logical vector
    calc_expr = paste0("sum(!is.na(", r_egen_args_conditional, "))")
  } else if (egen_func_name == "rank") {
    # Stata rank() without fieldstrustmissings returns missing for missing.
    # Stata rank() with fieldstrustmissings treats missing values as true values (usually largest) and assigns them a rank.
    # Stata's rank() uses the 'average' method for ties.
    if (is_fieldstrustmissings) {
      # Replace NA values with Inf to rank them highest.
      # Note: r_egen_args_conditional already applies if/in conditions, yielding NA for rows not meeting condition.
      # These NAs should also be treated as largest for ranking due to fieldstrustmissings.
      val_for_ranking = paste0("as.numeric(dplyr::if_else(is.na(", r_egen_args_conditional, "), Inf, ", r_egen_args_conditional, "))")
      calc_expr = paste0("as.numeric(base::rank(", val_for_ranking, ", ties.method = 'average', na.last = 'keep'))")
    } else {
      # Default Stata rank: NAs get NA ranks, and uses 'average' method for ties.
      calc_expr = paste0("as.numeric(base::rank(", r_egen_args_conditional, ", ties.method = 'average', na.last = 'keep'))")
    }
  } else if (egen_func_name == "median" || egen_func_name == "p50") {
    calc_expr = paste0("stats::median(", r_egen_args_conditional, ", na.rm = TRUE)")
  } else if (egen_func_name == "sd" || egen_func_name == "std") {
    calc_expr = paste0("stats::sd(", r_egen_args_conditional, ", na.rm = TRUE)")
  } else if (egen_func_name == "group") {
    # dplyr::cur_group_id() gives integer for each group.
    calc_expr = paste0("dplyr::cur_group_id()")
  } else if (egen_func_name == "tag") {
    # Stata tag(varlist) creates 1 for first observation in a group (defined by varlist) and 0 otherwise.
    calc_expr = paste0("as.numeric(dplyr::row_number() == 1)")
  } else if (egen_func_name == "rowtotal") {
    # FIX: Remove backticks from variable names as `translate_stata_expression_to_r` already adds them,
    # and `dplyr::all_of` expects bare column names (strings), not backticked strings.
    vars_for_rowop_list = stringi::stri_split_regex(r_egen_args, "\\s+")[[1]] # Use non-conditional args here
    vars_for_rowop_list = vars_for_rowop_list[!is.na(vars_for_rowop_list) & vars_for_rowop_list != ""] # Filter empty/NA
    vars_for_rowop_list = stringi::stri_replace_all_fixed(vars_for_rowop_list, "`", "") # Remove backticks

    # Stata rowtotal treats NA as 0 *before* summing.
    # Replace NA with 0 in the selected columns before summing.
    cols_selection_expr = paste0("dplyr::select(dplyr::cur_data_all(), dplyr::all_of(c('", paste(vars_for_rowop_list, collapse="','"), "')))")
    calc_expr = paste0("base::rowSums(", cols_selection_expr, " %>% replace(is.na(.), 0), na.rm = FALSE)")
    is_row_function = TRUE
  } else if (egen_func_name == "rowmean") {
    # FIX: Remove backticks from variable names for `dplyr::all_of`.
    vars_for_rowop_list = stringi::stri_split_regex(r_egen_args, "\\s+")[[1]] # Use non-conditional args here
    vars_for_rowop_list = vars_for_rowop_list[!is.na(vars_for_rowop_list) & vars_for_rowop_list != ""] # Filter empty/NA
    vars_for_rowop_list = stringi::stri_replace_all_fixed(vars_for_rowop_list, "`", "") # Remove backticks

    # Stata rowmean ignores NAs. base::rowMeans with na.rm = TRUE achieves this.
    cols_selection_expr = paste0("dplyr::select(dplyr::cur_data_all(), dplyr::all_of(c('", paste(vars_for_rowop_list, collapse="','"), "')))")
    calc_expr = paste0("base::rowMeans(", cols_selection_expr, ", na.rm = TRUE)")
    is_row_function = TRUE
  } else if (egen_func_name == "concat") {
    vars_to_concat_list = stringi::stri_split_regex(egen_args_str, "\\s+")[[1]]
    vars_to_concat_list = vars_to_concat_list[!is.na(vars_to_concat_list) & vars_to_concat_list != ""]

    if (length(vars_to_concat_list) == 0) {
      return(paste0("# egen concat() requires variables to concatenate."))
    }

    # Stata: If all variables in varlist are missing, newvar is missing. Otherwise, missing values are treated as empty strings.
    # Approach:
    # 1. Check if all input variables for a row are NA. If so, result is NA.
    # 2. Otherwise, for each variable, replace NA with "" and then concatenate.

    # Expression to check if all relevant variables in a row are NA.
    # Use data[['var_name']] for explicit column access.
    all_vars_na_check_list = paste0("is.na(data[['", vars_to_concat_list, "']])")
    all_vars_na_check_expr = paste0("(", paste0(all_vars_na_check_list, collapse = " & "), ")")

    # Arguments for stri_paste, with NAs replaced by empty strings
    stri_paste_args_with_na_empty = paste0("dplyr::if_else(is.na(as.character(data[['", vars_to_concat_list, "']])), \"\", as.character(data[['", vars_to_concat_list, "']]))", collapse = ", ")

    # Expression for the actual concatenation
    # Use na_empty = FALSE (default) because NAs are already handled.
    calc_expr = paste0("dplyr::if_else(", all_vars_na_check_expr, ", NA_character_, stringi::stri_paste(", stri_paste_args_with_na_empty, ", sep = ''))")

    is_row_function = TRUE # Concatenation is inherently row-wise.
  } else {
    return(paste0("# Egen function '", egen_func_name, "' not yet implemented."))
  }

  # Combine into a mutate statement
  full_mutate_expr = paste0("`", new_var, "` = ", calc_expr)


  # Determine actual grouping variables for dplyr::group_by
  group_vars_list_bare = character(0) 
  
  if (cmd_obj$is_by_prefix) {
    if (length(cmd_obj$by_group_vars) > 0 && !is.na(cmd_obj$by_group_vars[1])) {
      group_vars_list = stringi::stri_split_fixed(cmd_obj$by_group_vars, ",")[[1]]
      group_vars_list = group_vars_list[!is.na(group_vars_list) & group_vars_list != ""]
      if (length(group_vars_list) > 0) {
        group_vars_list_bare = group_vars_list # Assign just the bare names
      }
    }
  } else if (!is.na(options_str)) {
    by_opt_match = stringi::stri_match_first_regex(options_str, "\\bby\\s*\\(([^)]+)\\)")
    if (!is.na(by_opt_match[1,1])) {
      group_vars_list_bare = stringi::stri_split_regex(stringi::stri_trim_both(by_opt_match[1,2]), "\\s+")[[1]]
      group_vars_list_bare = group_vars_list_bare[!is.na(group_vars_list_bare) & group_vars_list_bare != ""]
    }
  }

  # For 'group' and 'tag' functions, the arguments also define the grouping
  if (egen_func_name %in% c("group", "tag")) {
    egen_func_args_list = stringi::stri_split_regex(egen_args_str, "\\s+")[[1]]
    egen_func_args_list = egen_func_args_list[!is.na(egen_func_args_list) & egen_func_args_list != ""]
    # Union of `by` variables and `egen` function arguments defines the group
    group_vars_list_bare = unique(c(group_vars_list_bare, egen_func_args_list))
  }


  # Determine variables for initial sorting for functions requiring internal sort (rank, group, tag)
  sort_vars_for_arrange = character(0)

  # Only sort temporarily if it's NOT a by-prefix command, but one of the order-sensitive egen functions
  if (!cmd_obj$is_by_prefix && length(group_vars_list_bare) > 0 && egen_func_name %in% c("rank", "group", "tag")) {
    sort_vars_for_arrange = unique(c(group_vars_list_bare))
    if (egen_func_name == "rank" && !is.na(egen_args_str) && egen_args_str != "") {
      # For rank, also sort by the argument of rank() if it's a variable
      rank_arg_var = stringi::stri_replace_all_fixed(r_egen_args, "`", "") # Remove backticks for comparison
      if (rank_arg_var %in% names(data)) { # Check if it's a valid variable name
        sort_vars_for_arrange = unique(c(sort_vars_for_arrange, rank_arg_var))
      }
    }
    sort_vars_for_arrange = sort_vars_for_arrange[!is.na(sort_vars_for_arrange) & sort_vars_for_arrange != ""]
  }

  r_code_lines = c()
  pipe_elements = list("data") # Start the pipe with the data object

  # Add arrange for `egen group/tag/rank` functions within the pipe, if not already handled by bysort command
  if (length(sort_vars_for_arrange) > 0 && !is_row_function) {
    arrange_vars_expr = paste0('!!!dplyr::syms(c("', paste0(sort_vars_for_arrange, collapse = '", "'), '"))')
    pipe_elements = c(pipe_elements, paste0("dplyr::arrange(", arrange_vars_expr, ")"))
  }


  # Add grouping and mutate steps
  if (length(group_vars_list_bare) > 0 && !is_row_function) {
    group_by_call_str = paste0('dplyr::group_by(!!!dplyr::syms(c("', paste0(group_vars_list_bare, collapse='", "'), '")))')
    pipe_elements = c(pipe_elements, group_by_call_str)
  }

  pipe_elements = c(pipe_elements, paste0("dplyr::mutate(", full_mutate_expr, ")"))

  if (length(group_vars_list_bare) > 0 && !is_row_function) {
    pipe_elements = c(pipe_elements, "dplyr::ungroup()")
  }

  # Restore original order if it was a temporary sort for egen functions without bysort prefix
  # This is handled by arranging by `stata2r_original_order_idx` after ungrouping.
  if (!cmd_obj$is_by_prefix && length(sort_vars_for_arrange) > 0 && !is_row_function && isTRUE(stata2r_env$has_original_order_idx)) {
    pipe_elements = c(pipe_elements, "dplyr::arrange(stata2r_original_order_idx)")
  }

  r_code_lines = c(r_code_lines, paste0("data = ", paste(pipe_elements, collapse = " %>% \n  ")))

   # Add comment about options if any were present but not handled (excluding by)
   options_str_cleaned = options_str
   if (!is.na(options_str_cleaned)) {
        options_str_cleaned = stringi::stri_replace_first_regex(options_str_cleaned, "\\bby\\s*\\([^)]+\\)", "")
        # Remove fieldstrustmissings from the options string if it was present
        options_str_cleaned = stringi::stri_replace_first_fixed(options_str_cleaned, "fieldstrustmissings", "")
        options_str_cleaned = stringi::stri_trim_both(stringi::stri_replace_all_regex(options_str_cleaned, ",+", ",")) # Clean up multiple commas
        options_str_cleaned = stringi::stri_replace_first_regex(options_str_cleaned, "^,+", "") # Remove leading comma
   }


   if (!is.na(options_str_cleaned) && options_str_cleaned != "") {
        r_code_lines = c(r_code_lines, paste0(" # Other options ignored: ", options_str_cleaned))
   }


  return(paste(r_code_lines, collapse="\n"))
}
```
!END_CHANGE_FILE t_egen.R
